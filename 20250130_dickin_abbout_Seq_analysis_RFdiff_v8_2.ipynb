{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Y0oHy3jySMVHHe4l0ui-3Izfg3mMhfSG",
      "authorship_tag": "ABX9TyNEVgFu/gMQOH1K686aIx0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/Biophysics-general/blob/main/20250130_dickin_abbout_Seq_analysis_RFdiff_v8_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AJ2WyL3YufKK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Sequence Analysis Pipeline with Cluster Images\n",
        "Author: [Your Name]\n",
        "Date: [Current Date]\n",
        "\n",
        "Description:\n",
        "This script performs sequence analysis with clustering visualization.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from scipy.cluster import hierarchy\n",
        "from joblib import Parallel, delayed\n",
        "import re\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "@dataclass\n",
        "class PipelineConfig:\n",
        "    \"\"\"Configuration settings for the analysis pipeline.\"\"\"\n",
        "    input_file: Path\n",
        "    output_dir: Path\n",
        "    max_sequences: Optional[int] = None\n",
        "    chunk_size: int = 1000\n",
        "    n_jobs: int = -1\n",
        "    dpi: int = 300\n",
        "    amino_acids: str = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "    distance_metric: str = \"hamming\"\n",
        "    linkage_method: str = \"average\"\n",
        "\n",
        "class SequenceAnalysisPipeline:\n",
        "    \"\"\"Main class for sequence analysis pipeline operations.\"\"\"\n",
        "\n",
        "    def __init__(self, config: PipelineConfig):\n",
        "        self.config = config\n",
        "        self.config.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self._setup_logging()\n",
        "\n",
        "    def _setup_logging(self) -> None:\n",
        "        \"\"\"Setup logging to file in output directory.\"\"\"\n",
        "        log_file = self.config.output_dir / \"pipeline.log\"\n",
        "        file_handler = logging.FileHandler(log_file)\n",
        "        file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "    def extract_designed_sequences(self) -> List[SeqRecord]:\n",
        "        \"\"\"Extract designed sequences with improved error handling and validation.\"\"\"\n",
        "        if not self.config.input_file.exists():\n",
        "            raise FileNotFoundError(f\"Input file not found: {self.config.input_file}\")\n",
        "\n",
        "        extracted_sequences = []\n",
        "        design_lengths = set()\n",
        "\n",
        "        logger.info(f\"Extracting sequences from {self.config.input_file}\")\n",
        "\n",
        "        for idx, record in enumerate(SeqIO.parse(self.config.input_file, \"fasta\")):\n",
        "            if self.config.max_sequences and idx >= self.config.max_sequences:\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                match = re.search(r'design:(\\d+).*n:(\\d+)', record.description)\n",
        "                if not match:\n",
        "                    logger.warning(f\"Skipping sequence {idx}: Could not parse description\")\n",
        "                    continue\n",
        "\n",
        "                new_id = f\"d{match.group(1)}_n{match.group(2)}\"\n",
        "\n",
        "                if '/' not in str(record.seq):\n",
        "                    logger.warning(f\"Skipping sequence {idx}: No '/' delimiter found\")\n",
        "                    continue\n",
        "\n",
        "                designed_seq = str(record.seq).split('/')[1].replace('-', '').strip()\n",
        "\n",
        "                if not designed_seq:\n",
        "                    logger.warning(f\"Skipping sequence {idx}: Empty sequence after processing\")\n",
        "                    continue\n",
        "\n",
        "                if not all(aa in self.config.amino_acids for aa in designed_seq):\n",
        "                    logger.warning(f\"Skipping sequence {idx}: Invalid amino acids found\")\n",
        "                    continue\n",
        "\n",
        "                design_lengths.add(len(designed_seq))\n",
        "                extracted_sequences.append(SeqRecord(Seq(designed_seq), id=new_id, description=\"\"))\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error processing sequence {idx}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not extracted_sequences:\n",
        "            raise ValueError(\"No valid sequences found in input file\")\n",
        "\n",
        "        if len(design_lengths) > 1:\n",
        "            logger.warning(f\"Multiple sequence lengths found: {design_lengths}\")\n",
        "\n",
        "        output_fasta = self.config.output_dir / \"extracted_sequences.fasta\"\n",
        "        SeqIO.write(extracted_sequences, output_fasta, \"fasta\")\n",
        "        logger.info(f\"Extracted {len(extracted_sequences)} sequences to {output_fasta}\")\n",
        "\n",
        "        return extracted_sequences\n",
        "\n",
        "    def one_hot_encode(self, sequences: List[str]) -> np.ndarray:\n",
        "        \"\"\"One-hot encode sequences with memory optimization.\"\"\"\n",
        "        aa_dict = {aa: i for i, aa in enumerate(self.config.amino_acids)}\n",
        "        seq_length = len(sequences[0])\n",
        "        n_sequences = len(sequences)\n",
        "\n",
        "        encoding = np.zeros((n_sequences, seq_length * len(self.config.amino_acids)), dtype=np.int8)\n",
        "\n",
        "        for i, seq in enumerate(sequences):\n",
        "            for j, aa in enumerate(seq):\n",
        "                if aa in aa_dict:\n",
        "                    encoding[i, j * len(self.config.amino_acids) + aa_dict[aa]] = 1\n",
        "\n",
        "        return encoding\n",
        "\n",
        "    def compute_distance_matrix(self, encoded_seqs: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Compute distance matrix with parallel processing.\"\"\"\n",
        "        logger.info(\"Computing distance matrix...\")\n",
        "        distances = pdist(encoded_seqs, metric=self.config.distance_metric)\n",
        "        return squareform(distances)\n",
        "\n",
        "    def create_visualizations(self, distance_matrix: np.ndarray, sequence_names: List[str]) -> None:\n",
        "        \"\"\"Create and save visualizations.\"\"\"\n",
        "        logger.info(\"Generating visualizations...\")\n",
        "\n",
        "        # Create similarity heatmap\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(1 - distance_matrix[:50, :50],\n",
        "                   cmap=\"viridis\",\n",
        "                   square=True,\n",
        "                   xticklabels=sequence_names[:50],\n",
        "                   yticklabels=sequence_names[:50])\n",
        "        plt.title(\"Sequence Similarity Matrix (First 50 Sequences)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(self.config.output_dir / \"similarity_heatmap.png\",\n",
        "                   dpi=self.config.dpi)\n",
        "        plt.close()\n",
        "\n",
        "        # Create phylogenetic tree\n",
        "        condensed_dist = squareform(distance_matrix)\n",
        "        Z = hierarchy.linkage(condensed_dist, method=self.config.linkage_method)\n",
        "\n",
        "        plt.figure(figsize=(20, 10))\n",
        "        dendro = hierarchy.dendrogram(Z,\n",
        "                                    labels=sequence_names,\n",
        "                                    leaf_rotation=90,\n",
        "                                    leaf_font_size=8)\n",
        "        plt.title(\"Sequence Similarity Tree\")\n",
        "        plt.xlabel(\"Sequence ID\")\n",
        "        plt.ylabel(\"Distance\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(self.config.output_dir / \"sequence_tree.png\",\n",
        "                   dpi=self.config.dpi)\n",
        "        plt.close()\n",
        "\n",
        "        # Save individual cluster images\n",
        "        cluster_colors = set(dendro['color_list'])\n",
        "        leaf_colors = dendro['color_list']\n",
        "        leaves = dendro['leaves']\n",
        "\n",
        "        for color_idx, color in enumerate(cluster_colors):\n",
        "            # Find all leaves in this cluster\n",
        "            cluster_leaves = [leaves[i] for i, c in enumerate(leaf_colors) if c == color]\n",
        "            cluster_indices = np.isin(range(len(sequence_names)), cluster_leaves)\n",
        "\n",
        "            # Extract sub-matrix for this cluster\n",
        "            cluster_dist = distance_matrix[cluster_indices][:, cluster_indices]\n",
        "            cluster_names = [sequence_names[i] for i in range(len(sequence_names)) if cluster_indices[i]]\n",
        "\n",
        "            # Create cluster-specific linkage matrix\n",
        "            cluster_Z = hierarchy.linkage(squareform(cluster_dist), method=self.config.linkage_method)\n",
        "\n",
        "            # Calculate figure size based on number of sequences\n",
        "            seq_count = len(cluster_names)\n",
        "            width = max(20, seq_count * 0.15)\n",
        "\n",
        "            plt.figure(figsize=(width, 10))\n",
        "            plt.subplots_adjust(bottom=0.25)\n",
        "\n",
        "            # Create dendrogram with angled labels\n",
        "            hierarchy.dendrogram(\n",
        "                cluster_Z,\n",
        "                labels=cluster_names,\n",
        "                leaf_rotation=45,\n",
        "                leaf_font_size=8,\n",
        "                link_color_func=lambda x: color\n",
        "            )\n",
        "\n",
        "            # Calculate dynamic figure dimensions based on number of sequences\n",
        "            seq_count = len(cluster_names)\n",
        "            width = max(20, seq_count * 0.2)  # Increase width multiplier\n",
        "            height = 12  # Taller figure to accommodate labels\n",
        "\n",
        "            plt.figure(figsize=(width, height))\n",
        "\n",
        "            # Create dendrogram without labels first\n",
        "            dend = hierarchy.dendrogram(\n",
        "                cluster_Z,\n",
        "                labels=None,  # No labels initially\n",
        "                leaf_rotation=45,\n",
        "                leaf_font_size=8,\n",
        "                link_color_func=lambda x: color\n",
        "            )\n",
        "\n",
        "            ax = plt.gca()\n",
        "\n",
        "            # Get the x-coordinates and labels in the correct order\n",
        "            xticks = ax.get_xticks()\n",
        "            labels = [cluster_names[i] for i in dend['leaves']]\n",
        "\n",
        "            # Remove existing ticks and labels\n",
        "            ax.set_xticks([])\n",
        "            ax.set_xlabel('')  # Remove x-axis label\n",
        "\n",
        "            # Add custom positioned labels with more spacing\n",
        "            # Moving labels up by adjusting y_offset values\n",
        "            for idx, (x, label) in enumerate(zip(xticks, labels)):\n",
        "                # Even labels at base position, odd labels offset\n",
        "                y_offset = 0.02 if idx % 2 == 0 else -0.04  # Moved up (positive values)\n",
        "                alignment = 'left' if idx % 2 == 0 else 'right'\n",
        "\n",
        "                ax.text(x, y_offset, label,\n",
        "                       rotation=45,\n",
        "                       ha=alignment,\n",
        "                       va='top',\n",
        "                       fontsize=8)\n",
        "\n",
        "            # Set title and labels\n",
        "            plt.title(f\"Cluster {color_idx}: {len(cluster_names)} sequences\")\n",
        "            plt.ylabel(\"Distance\")\n",
        "\n",
        "            # Adjust margins - reduced bottom margin since labels are higher\n",
        "            plt.subplots_adjust(bottom=0.15)  # Reduced from 0.3\n",
        "\n",
        "            # Save with tight bbox to include all labels\n",
        "            plt.savefig(self.config.output_dir / f\"cluster_{color_idx}.png\",\n",
        "                       dpi=self.config.dpi,\n",
        "                       bbox_inches='tight',\n",
        "                       pad_inches=0.5)  # Add padding\n",
        "            plt.close()\n",
        "\n",
        "            plt.title(f\"Cluster {color_idx}: {len(cluster_names)} sequences\")\n",
        "            plt.xlabel(\"Sequence ID\")\n",
        "            plt.ylabel(\"Distance\")\n",
        "\n",
        "            plt.tight_layout(rect=[0, 0.2, 1, 1])\n",
        "            plt.savefig(self.config.output_dir / f\"cluster_{color_idx}.png\",\n",
        "                       dpi=self.config.dpi,\n",
        "                       bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "    def run(self) -> Tuple[List[SeqRecord], np.ndarray]:\n",
        "        \"\"\"Run the complete analysis pipeline.\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting sequence analysis pipeline...\")\n",
        "\n",
        "            sequences = self.extract_designed_sequences()\n",
        "            sequence_list = [str(seq.seq) for seq in sequences]\n",
        "            sequence_names = [seq.id for seq in sequences]\n",
        "\n",
        "            encoded_seqs = self.one_hot_encode(sequence_list)\n",
        "            distance_matrix = self.compute_distance_matrix(encoded_seqs)\n",
        "            self.create_visualizations(distance_matrix, sequence_names)\n",
        "\n",
        "            logger.info(\"Analysis pipeline completed successfully\")\n",
        "            return sequences, distance_matrix\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Pipeline failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main entry point with example usage.\"\"\"\n",
        "    config = PipelineConfig(\n",
        "        input_file=Path(\"/content/drive/MyDrive/Fasta-files/3NOB_90-110/3NOB_90-110_design.fasta\"),\n",
        "        output_dir=Path(\"/content/drive/MyDrive/Fasta-files/3NOB_90-110/analysis_output\"),\n",
        "        max_sequences=None,\n",
        "        chunk_size=1000,\n",
        "        n_jobs=-1,\n",
        "        dpi=300\n",
        "    )\n",
        "\n",
        "    pipeline = SequenceAnalysisPipeline(config)\n",
        "    sequences, distance_matrix = pipeline.run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeSDPO33tOPF",
        "outputId": "52586c51-4fb5-4255-8af3-7ab013561c89"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UzUBMUKRxWk9"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}