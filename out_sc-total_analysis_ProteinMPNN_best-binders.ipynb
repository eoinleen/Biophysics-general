{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fwYwVmDrlgQsqUZ38JZ8HjHnMr_DSWuV",
      "authorship_tag": "ABX9TyMLhcunXMCu7skI+bKBbiUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/Biophysics-general/blob/main/out_sc-total_analysis_ProteinMPNN_best-binders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3_gD5OhjgZ9"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Integrated Protein Binder Analysis & Visualization Script\n",
        "\n",
        "This script performs comprehensive analysis of protein binding scores from\n",
        "out.sc files and generates visualizations with transparent backgrounds.\n",
        "\n",
        "Specifically configured for Google Colab with default paths set to:\n",
        "- Input: /content/drive/MyDrive/Analysis-text-files-ProteinMPNN/2025031-binder0/out.sc\n",
        "- Output: /content/drive/MyDrive/Analysis-text-files-ProteinMPNN/2025031-binder0/\n",
        "\n",
        "For Google Colab usage:\n",
        "1. First mount your Google Drive:\n",
        "   from google.colab import drive\n",
        "   drive.mount('/content/drive')\n",
        "\n",
        "2. Run the script with default paths:\n",
        "   !python protein_analysis.py\n",
        "\n",
        "Author: Claude\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import seaborn as sns\n",
        "\n",
        "# Set plot style for transparent backgrounds\n",
        "plt.rcParams['figure.facecolor'] = 'none'\n",
        "plt.rcParams['axes.facecolor'] = 'none'\n",
        "plt.rcParams['savefig.facecolor'] = 'none'\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"Parse command line arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser(description='Analyze and visualize protein binding data')\n",
        "    parser.add_argument('-f', '--file', default='/content/drive/MyDrive/Analysis-text-files-ProteinMPNN/2025031-binder0/out.sc',\n",
        "                       help='Input score file (out.sc format) - default is set for the specific project')\n",
        "    parser.add_argument('-o', '--output', default='/content/drive/MyDrive/Analysis-text-files-ProteinMPNN/2025031-binder0',\n",
        "                       help='Output directory (default: specific project directory)')\n",
        "    parser.add_argument('-n', '--number', type=int, default=30, help='Number of top candidates to consider (default: 30)')\n",
        "    parser.add_argument('-v', '--visualize-only', action='store_true', help='Skip analysis and only visualize existing results')\n",
        "    return parser.parse_args()\n",
        "\n",
        "def run_analysis(input_file, output_file, top_n):\n",
        "    \"\"\"Run the binding score analysis.\"\"\"\n",
        "    print(f\"Analyzing protein binding data from {input_file}...\")\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(input_file):\n",
        "        print(f\"Error: File {input_file} not found.\")\n",
        "        return False\n",
        "\n",
        "    # Read the input file\n",
        "    try:\n",
        "        with open(input_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading input file: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Extract header\n",
        "    header = None\n",
        "    for line in lines:\n",
        "        if line.startswith(\"SCORE:\") and \"binder_aligned_rmsd\" in line:\n",
        "            header = line.replace(\"SCORE:\", \"\").strip()\n",
        "            break\n",
        "\n",
        "    if not header:\n",
        "        print(\"Error: Could not find header in input file.\")\n",
        "        return False\n",
        "\n",
        "    # Create temporary files for each category\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    plddt_file = os.path.join(temp_dir, \"plddt_binder.txt\")\n",
        "    pae_file = os.path.join(temp_dir, \"pae_interaction.txt\")\n",
        "    rmsd_file = os.path.join(temp_dir, \"binder_aligned_rmsd.txt\")\n",
        "    combined_file = os.path.join(temp_dir, \"combined.txt\")\n",
        "\n",
        "    # Extract data rows (skip header)\n",
        "    data_rows = [line for line in lines if line.startswith(\"SCORE:\") and \"binder_aligned_rmsd\" not in line]\n",
        "\n",
        "    # Get total number of designs\n",
        "    total_designs = len(data_rows)\n",
        "    if top_n > total_designs:\n",
        "        top_n = total_designs\n",
        "        print(f\"Note: Only {total_designs} designs available, using all of them.\")\n",
        "\n",
        "    # Parse rows into a DataFrame\n",
        "    data = []\n",
        "    for line in data_rows:\n",
        "        row = line.replace(\"SCORE:\", \"\").strip().split()\n",
        "        # Extract values and ensure description is handled correctly\n",
        "        values = row[:len(header.split())-1]\n",
        "        description = \" \".join(row[len(header.split())-1:])\n",
        "        data.append(values + [description])\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data, columns=header.split())\n",
        "\n",
        "    # Convert numeric columns\n",
        "    numeric_cols = ['binder_aligned_rmsd', 'pae_binder', 'pae_interaction',\n",
        "                   'pae_target', 'plddt_binder', 'plddt_target',\n",
        "                   'plddt_total', 'target_aligned_rmsd', 'time']\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # Create sorted DataFrames for each metric\n",
        "    plddt_df = df.sort_values(by='plddt_binder', ascending=False).reset_index(drop=True)\n",
        "    pae_df = df.sort_values(by='pae_interaction', ascending=True).reset_index(drop=True)\n",
        "    rmsd_df = df.sort_values(by='binder_aligned_rmsd', ascending=True).reset_index(drop=True)\n",
        "\n",
        "    # Get top designs for each metric\n",
        "    plddt_designs = set(plddt_df.head(top_n)['description'].tolist())\n",
        "    pae_designs = set(pae_df.head(top_n)['description'].tolist())\n",
        "    rmsd_designs = set(rmsd_df.head(top_n)['description'].tolist())\n",
        "\n",
        "    # Find designs in all three sets\n",
        "    combined_designs = plddt_designs.intersection(pae_designs, rmsd_designs)\n",
        "\n",
        "    # Create combined DataFrame with these designs, sorted by PAE interaction\n",
        "    combined_df = df[df['description'].isin(combined_designs)].sort_values(by='pae_interaction', ascending=True)\n",
        "\n",
        "    # Write results to output file\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(\"COMPREHENSIVE PROTEIN BINDER ANALYSIS\\n\")\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(f\"Input file: {input_file}\\n\")\n",
        "        f.write(f\"Total designs analyzed: {total_designs}\\n\")\n",
        "        f.write(f\"Top candidates considered per metric: {top_n}\\n\")\n",
        "        f.write(f\"Date of analysis: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(\"=============================================\\n\\n\")\n",
        "\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(f\"TOP {top_n} DESIGNS BY PLDDT_BINDER (HIGHER IS BETTER)\\n\")\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(f\"SCORE: {header}\\n\")\n",
        "        for _, row in plddt_df.head(top_n).iterrows():\n",
        "            values = \" \".join([f\"{row[col]}\" for col in plddt_df.columns if col != 'description'])\n",
        "            f.write(f\"SCORE: {values} {row['description']}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(f\"TOP {top_n} DESIGNS BY PAE_INTERACTION (LOWER IS BETTER)\\n\")\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(f\"SCORE: {header}\\n\")\n",
        "        for _, row in pae_df.head(top_n).iterrows():\n",
        "            values = \" \".join([f\"{row[col]}\" for col in pae_df.columns if col != 'description'])\n",
        "            f.write(f\"SCORE: {values} {row['description']}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(f\"TOP {top_n} DESIGNS BY BINDER_ALIGNED_RMSD (LOWER IS BETTER)\\n\")\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(f\"SCORE: {header}\\n\")\n",
        "        for _, row in rmsd_df.head(top_n).iterrows():\n",
        "            values = \" \".join([f\"{row[col]}\" for col in rmsd_df.columns if col != 'description'])\n",
        "            f.write(f\"SCORE: {values} {row['description']}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "        f.write(\"=============================================\\n\")\n",
        "        f.write(f\"DESIGNS APPEARING IN ALL THREE TOP {top_n} LISTS\\n\")\n",
        "        f.write(\"RANKED BY PAE_INTERACTION (LOWER IS BETTER)\\n\")\n",
        "        f.write(\"=============================================\\n\")\n",
        "\n",
        "        if combined_df.empty:\n",
        "            f.write(\"No designs found in all three categories.\\n\")\n",
        "        else:\n",
        "            f.write(f\"SCORE: {header}\\n\")\n",
        "            for _, row in combined_df.iterrows():\n",
        "                values = \" \".join([f\"{row[col]}\" for col in combined_df.columns if col != 'description'])\n",
        "                f.write(f\"SCORE: {values} {row['description']}\\n\")\n",
        "\n",
        "            # Extract best design info\n",
        "            best_design = combined_df.iloc[0]['description']\n",
        "            best_pae = combined_df.iloc[0]['pae_interaction']\n",
        "            best_plddt = combined_df.iloc[0]['plddt_binder']\n",
        "            best_rmsd = combined_df.iloc[0]['binder_aligned_rmsd']\n",
        "\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"=============================================\\n\")\n",
        "            f.write(\"SUMMARY OF BEST OVERALL DESIGN\\n\")\n",
        "            f.write(\"=============================================\\n\")\n",
        "            f.write(f\"Best overall design: {best_design}\\n\")\n",
        "            f.write(f\"PAE_interaction: {best_pae} (lower is better)\\n\")\n",
        "            f.write(f\"PLDDT_binder: {best_plddt} (higher is better)\\n\")\n",
        "            f.write(f\"Binder_aligned_RMSD: {best_rmsd} (lower is better)\\n\")\n",
        "\n",
        "    print(f\"Analysis complete! Results written to {output_file}\")\n",
        "    print(f\"Found {len(combined_designs)} designs that appear in all three top {top_n} lists.\")\n",
        "\n",
        "    # Clean up temporary directory\n",
        "    import shutil\n",
        "    shutil.rmtree(temp_dir)\n",
        "\n",
        "    return True\n",
        "\n",
        "def parse_scores_section(section_content):\n",
        "    \"\"\"Parse scores from a section of the analysis file.\"\"\"\n",
        "    if not section_content or \"No designs found\" in section_content:\n",
        "        return None\n",
        "\n",
        "    lines = section_content.strip().split(\"\\n\")\n",
        "    # Find the header line\n",
        "    header_idx = -1\n",
        "    for i, line in enumerate(lines):\n",
        "        if \"SCORE:\" in line and \"description\" in line:\n",
        "            header_idx = i\n",
        "            break\n",
        "\n",
        "    if header_idx == -1:\n",
        "        return None\n",
        "\n",
        "    # Parse header\n",
        "    header = lines[header_idx].replace(\"SCORE:\", \"\").strip().split()\n",
        "\n",
        "    # Parse data rows\n",
        "    data = []\n",
        "    for line in lines[header_idx+1:]:\n",
        "        if line.strip() and \"SCORE:\" in line:\n",
        "            row = line.replace(\"SCORE:\", \"\").strip().split()\n",
        "            # Ensure the row has enough elements\n",
        "            if len(row) >= len(header):\n",
        "                data_row = row[:len(header)-1] + [\" \".join(row[len(header)-1:])]\n",
        "                data.append(data_row)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data, columns=header)\n",
        "\n",
        "    # Convert numeric columns to float\n",
        "    numeric_cols = ['binder_aligned_rmsd', 'pae_binder', 'pae_interaction',\n",
        "                   'pae_target', 'plddt_binder', 'plddt_target',\n",
        "                   'plddt_total', 'target_aligned_rmsd', 'time']\n",
        "\n",
        "    for col in numeric_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    return df\n",
        "\n",
        "def extract_section(content, section_title, num_lines=None):\n",
        "    \"\"\"Extract a section from the analysis file.\"\"\"\n",
        "    pattern = f\"={{{5,}}}\\n{section_title}\\n={{{5,}}}\"\n",
        "    match = re.search(pattern, content)\n",
        "    if not match:\n",
        "        return None\n",
        "\n",
        "    start_idx = match.end()\n",
        "    next_section = re.search(\"={5,}\", content[start_idx:])\n",
        "\n",
        "    if next_section:\n",
        "        end_idx = start_idx + next_section.start()\n",
        "        section_content = content[start_idx:end_idx].strip()\n",
        "    else:\n",
        "        section_content = content[start_idx:].strip()\n",
        "\n",
        "    if num_lines:\n",
        "        section_content = \"\\n\".join(section_content.split(\"\\n\")[:num_lines])\n",
        "\n",
        "    return section_content\n",
        "\n",
        "def create_correlation_heatmap(combined_df, output_path):\n",
        "    \"\"\"Create correlation heatmap between metrics.\"\"\"\n",
        "    if combined_df is None or combined_df.empty:\n",
        "        return\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Select only numeric columns for correlation\n",
        "    numeric_cols = ['binder_aligned_rmsd', 'pae_binder', 'pae_interaction',\n",
        "                   'pae_target', 'plddt_binder', 'plddt_target',\n",
        "                   'plddt_total', 'target_aligned_rmsd', 'time']\n",
        "\n",
        "    # Filter to only include columns that exist\n",
        "    available_cols = [col for col in numeric_cols if col in combined_df.columns]\n",
        "    numeric_df = combined_df[available_cols].copy()\n",
        "\n",
        "    # Calculate correlation\n",
        "    corr = numeric_df.corr()\n",
        "\n",
        "    # Create custom colormap (blue to white to red)\n",
        "    colors = [\"#4363d8\", \"#ffffff\", \"#e6194B\"]\n",
        "    cmap = LinearSegmentedColormap.from_list(\"custom_diverging\", colors, N=256)\n",
        "\n",
        "    # Create heatmap\n",
        "    mask = np.zeros_like(corr, dtype=bool)\n",
        "    mask[np.triu_indices_from(mask, k=1)] = True\n",
        "\n",
        "    with sns.axes_style(\"white\"):\n",
        "        sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
        "                    annot=True, fmt=\".2f\", square=True, linewidths=.5,\n",
        "                    cbar_kws={\"shrink\": .7})\n",
        "\n",
        "    plt.title('Correlation between Binding Metrics', fontsize=16, pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight', transparent=True)\n",
        "    plt.close()\n",
        "\n",
        "def create_parallel_coordinates(combined_df, output_path):\n",
        "    \"\"\"Create parallel coordinates plot for the top designs.\"\"\"\n",
        "    if combined_df is None or combined_df.empty:\n",
        "        return\n",
        "\n",
        "    # Select columns to include in parallel plot\n",
        "    cols_to_plot = ['binder_aligned_rmsd', 'pae_interaction', 'plddt_binder',\n",
        "                    'plddt_total', 'description']\n",
        "\n",
        "    # Filter to only columns that exist\n",
        "    available_cols = [col for col in cols_to_plot if col in combined_df.columns]\n",
        "\n",
        "    if set(available_cols) - set(['description']) and 'description' in available_cols:\n",
        "        plot_df = combined_df[available_cols].copy()\n",
        "\n",
        "        # Normalize the data for better visualization\n",
        "        for col in plot_df.columns:\n",
        "            if col != 'description':\n",
        "                if col.startswith('plddt'):\n",
        "                    # For plddt higher is better, so we invert it for consistent direction\n",
        "                    plot_df[col] = 1 - (plot_df[col] - plot_df[col].min()) / (plot_df[col].max() - plot_df[col].min() + 1e-10)\n",
        "                else:\n",
        "                    # For other metrics lower is better\n",
        "                    plot_df[col] = (plot_df[col] - plot_df[col].min()) / (plot_df[col].max() - plot_df[col].min() + 1e-10)\n",
        "\n",
        "        # Create the plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        pd.plotting.parallel_coordinates(\n",
        "            plot_df, 'description',\n",
        "            colormap=plt.cm.viridis,\n",
        "            alpha=0.7\n",
        "        )\n",
        "\n",
        "        plt.title('Parallel Coordinates Plot of Top Designs', fontsize=16)\n",
        "        plt.xticks(rotation=30)\n",
        "        plt.ylabel('Normalized Values (lower is better for all metrics)')\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(output_path, dpi=300, bbox_inches='tight', transparent=True)\n",
        "        plt.close()\n",
        "\n",
        "def create_scatterplot_matrix(combined_df, output_path):\n",
        "    \"\"\"Create scatterplot matrix for the combined metrics.\"\"\"\n",
        "    if combined_df is None or combined_df.empty:\n",
        "        return\n",
        "\n",
        "    # Select metrics to plot\n",
        "    metrics = ['binder_aligned_rmsd', 'pae_interaction', 'plddt_binder', 'plddt_total']\n",
        "\n",
        "    # Filter to only include columns that exist\n",
        "    available_metrics = [col for col in metrics if col in combined_df.columns]\n",
        "\n",
        "    if len(available_metrics) > 1:\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        scatter_df = combined_df[available_metrics + ['description']].copy()\n",
        "\n",
        "        # Create pairplot\n",
        "        g = sns.pairplot(scatter_df,\n",
        "                        vars=available_metrics,\n",
        "                        diag_kind='kde',\n",
        "                        plot_kws={'alpha': 0.6, 's': 80, 'edgecolor': 'k', 'linewidth': 0.5},\n",
        "                        diag_kws={'fill': True, 'alpha': 0.6})\n",
        "\n",
        "        # Add titles and adjust layout\n",
        "        g.fig.suptitle('Scatterplot Matrix of Binding Metrics', fontsize=16, y=1.02)\n",
        "        g.fig.tight_layout()\n",
        "\n",
        "        # Save with transparent background\n",
        "        g.fig.savefig(output_path, dpi=300, bbox_inches='tight', transparent=True)\n",
        "        plt.close()\n",
        "\n",
        "def create_ranking_barplots(plddt_df, pae_df, rmsd_df, output_dir):\n",
        "    \"\"\"Create bar plots for top designs by each metric.\"\"\"\n",
        "    metrics = [\n",
        "        {'df': plddt_df, 'metric': 'plddt_binder', 'title': 'Top Designs by PLDDT_binder',\n",
        "         'color': 'green', 'higher_better': True, 'filename': 'top_plddt_binder.png'},\n",
        "        {'df': pae_df, 'metric': 'pae_interaction', 'title': 'Top Designs by PAE_interaction',\n",
        "         'color': 'blue', 'higher_better': False, 'filename': 'top_pae_interaction.png'},\n",
        "        {'df': rmsd_df, 'metric': 'binder_aligned_rmsd', 'title': 'Top Designs by Binder_aligned_RMSD',\n",
        "         'color': 'purple', 'higher_better': False, 'filename': 'top_binder_rmsd.png'}\n",
        "    ]\n",
        "\n",
        "    for item in metrics:\n",
        "        df = item['df']\n",
        "        if df is None or df.empty:\n",
        "            continue\n",
        "\n",
        "        metric = item['metric']\n",
        "        if metric not in df.columns:\n",
        "            continue\n",
        "\n",
        "        # Sort data and limit to top 10 for visualization\n",
        "        if item['higher_better']:\n",
        "            sorted_df = df.sort_values(by=metric, ascending=False).head(10)\n",
        "        else:\n",
        "            sorted_df = df.sort_values(by=metric, ascending=True).head(10)\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Create horizontal bar chart\n",
        "        bars = plt.barh(sorted_df['description'], sorted_df[metric], color=item['color'], alpha=0.7)\n",
        "\n",
        "        # Add value labels\n",
        "        for bar in bars:\n",
        "            width = bar.get_width()\n",
        "            plt.text(width + (width * 0.01),\n",
        "                    bar.get_y() + bar.get_height()/2,\n",
        "                    f'{width:.2f}',\n",
        "                    ha='left', va='center')\n",
        "\n",
        "        # Add titles and labels\n",
        "        plt.xlabel(metric)\n",
        "        plt.ylabel('Design')\n",
        "        plt.title(item['title'], fontsize=16)\n",
        "\n",
        "        # Direction indicator\n",
        "        direction = \"Higher is better\" if item['higher_better'] else \"Lower is better\"\n",
        "        plt.figtext(0.5, 0.01, direction, ha='center', fontsize=12)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        output_path = os.path.join(output_dir, item['filename'])\n",
        "        plt.savefig(output_path, dpi=300, bbox_inches='tight', transparent=True)\n",
        "        plt.close()\n",
        "\n",
        "def visualize_results(analysis_file, output_dir):\n",
        "    \"\"\"Create visualizations from analysis file.\"\"\"\n",
        "    print(f\"Generating visualizations from {analysis_file}...\")\n",
        "\n",
        "    if not os.path.exists(analysis_file):\n",
        "        print(f\"Error: Analysis file {analysis_file} not found.\")\n",
        "        return False\n",
        "\n",
        "    # Read the analysis file\n",
        "    with open(analysis_file, 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Extract sections\n",
        "    plddt_section = extract_section(content, \"TOP .* DESIGNS BY PLDDT_BINDER\")\n",
        "    pae_section = extract_section(content, \"TOP .* DESIGNS BY PAE_INTERACTION\")\n",
        "    rmsd_section = extract_section(content, \"TOP .* DESIGNS BY BINDER_ALIGNED_RMSD\")\n",
        "    combined_section = extract_section(content, \"DESIGNS APPEARING IN ALL THREE TOP .* LISTS\")\n",
        "\n",
        "    # Parse data from sections\n",
        "    plddt_df = parse_scores_section(plddt_section)\n",
        "    pae_df = parse_scores_section(pae_section)\n",
        "    rmsd_df = parse_scores_section(rmsd_section)\n",
        "    combined_df = parse_scores_section(combined_section)\n",
        "\n",
        "    # Create plots\n",
        "    print(\"Generating plots...\")\n",
        "\n",
        "    # 1. Create correlation heatmap\n",
        "    print(\"Creating correlation heatmap...\")\n",
        "    corr_output = os.path.join(output_dir, \"metric_correlations.png\")\n",
        "    create_correlation_heatmap(combined_df, corr_output)\n",
        "\n",
        "    # 2. Create parallel coordinates plot\n",
        "    print(\"Creating parallel coordinates plot...\")\n",
        "    parallel_output = os.path.join(output_dir, \"parallel_coordinates.png\")\n",
        "    create_parallel_coordinates(combined_df, parallel_output)\n",
        "\n",
        "    # 3. Create scatterplot matrix\n",
        "    print(\"Creating scatterplot matrix...\")\n",
        "    scatter_output = os.path.join(output_dir, \"scatterplot_matrix.png\")\n",
        "    create_scatterplot_matrix(combined_df, scatter_output)\n",
        "\n",
        "    # 4. Create ranking barplots\n",
        "    print(\"Creating ranking barplots...\")\n",
        "    create_ranking_barplots(plddt_df, pae_df, rmsd_df, output_dir)\n",
        "\n",
        "    print(f\"All plots saved to {output_dir}\")\n",
        "    print(\"Plots generated:\")\n",
        "    print(f\"1. {os.path.basename(corr_output)} - Correlation heatmap between metrics\")\n",
        "    print(f\"2. {os.path.basename(parallel_output)} - Parallel coordinates plot of top designs\")\n",
        "    print(f\"3. {os.path.basename(scatter_output)} - Scatterplot matrix of binding metrics\")\n",
        "    print(\"4. top_plddt_binder.png - Bar chart of top designs by PLDDT score\")\n",
        "    print(\"5. top_pae_interaction.png - Bar chart of top designs by PAE interaction\")\n",
        "    print(\"6. top_binder_rmsd.png - Bar chart of top designs by binder RMSD\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function.\"\"\"\n",
        "    # First check if running in Google Colab and mount drive if needed\n",
        "    try:\n",
        "        import google.colab\n",
        "        # We're in Colab, check if drive is mounted\n",
        "        if not os.path.exists('/content/drive'):\n",
        "            print(\"Mounting Google Drive...\")\n",
        "            from google.colab import drive\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"Google Drive mounted successfully.\")\n",
        "    except ImportError:\n",
        "        # Not in Colab, continue normally\n",
        "        pass\n",
        "\n",
        "    # Parse arguments\n",
        "    args = parse_args()\n",
        "\n",
        "    # Verify input file path\n",
        "    if not os.path.exists(args.file):\n",
        "        print(f\"WARNING: Input file {args.file} not found.\")\n",
        "        user_input = input(\"Would you like to specify a different path? (y/n): \")\n",
        "        if user_input.lower() == 'y':\n",
        "            new_path = input(\"Enter the path to your out.sc file: \")\n",
        "            args.file = new_path\n",
        "\n",
        "    # Determine output directory\n",
        "    output_dir = args.output\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Analysis file path\n",
        "    analysis_file = os.path.join(output_dir, \"0_top_binders_analysis.txt\")\n",
        "\n",
        "    print(f\"Input file: {args.file}\")\n",
        "    print(f\"Output directory: {output_dir}\")\n",
        "    print(f\"Analysis file will be saved as: {analysis_file}\")\n",
        "\n",
        "    # Run analysis if not skipped\n",
        "    if not args.visualize_only:\n",
        "        success = run_analysis(args.file, analysis_file, args.number)\n",
        "        if not success:\n",
        "            return\n",
        "\n",
        "    # Create visualizations\n",
        "    visualize_results(analysis_file, output_dir)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbTMGizWti2X",
        "outputId": "f8e260c3-d053-45f9-f363-0387506402c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}