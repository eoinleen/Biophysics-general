{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOEvPpdelwIf3rFxhD1XLQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eoinleen/Biophysics-general/blob/main/Total_analysis_RFdiff_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1W_jgO35bMgY"
      },
      "outputs": [],
      "source": [
        "1  \"\"\"\n",
        "2  RFdiffusion Structure Analysis and Sequence Extraction Tool\n",
        "3  ========================================================\n",
        "4  Created: January 31, 2025\n",
        "5  Authors: Original Analysis - Dr. Eoin Leen, University of Leeds\n",
        "6           Visualization & Integration - Claude AI & Dr. Eoin Leen\n",
        "7  Version: 2.0\n",
        "8\n",
        "9  Purpose:\n",
        "10 --------\n",
        "11 Combined pipeline for:\n",
        "12 1. Structural analysis of PDB files\n",
        "13 2. AF2 score visualization\n",
        "14 3. Sequence extraction and formatting\n",
        "15 4. Generation of publication-ready visualizations\n",
        "16\n",
        "17 Input Required:\n",
        "18 -------------\n",
        "19 1. Directory containing PDB files\n",
        "20 2. af2_scores.csv file in same directory containing:\n",
        "21    - design: Design number\n",
        "22    - n: Sequence number\n",
        "23    - seq: Sequences in format \"sequence1/sequence2\"\n",
        "24    - i_pae: iPAE scores\n",
        "25    - Other AF2 metrics\n",
        "26\n",
        "27 Output Generated:\n",
        "28 ---------------\n",
        "29 1. PowerPoint presentation with:\n",
        "30    - Slide 1: Structure-function correlation plots\n",
        "31    - Slide 2: iPAE score visualization\n",
        "32    - Slide 3: Top 10 sequences by iPAE score\n",
        "33    - Slide 4: Detailed interface analysis for structures with i_PAE < 7.5\n",
        "34 2. Combined FASTA file with all sequences\n",
        "35 3. CSV file with combined structural analysis\n",
        "36\n",
        "37 Analysis Parameters:\n",
        "38 ------------------\n",
        "39 1. Hydrogen Bonds:\n",
        "40    - Distance cutoff: O-N distance < 3.5 Å\n",
        "41    - Calculated between backbone atoms only\n",
        "42    - Only inter-chain H-bonds counted\n",
        "43\n",
        "44 2. Salt Bridges:\n",
        "45    - Distance cutoff: < 4.0 Å between any atoms of residue pairs\n",
        "46    - Residue pairs considered:\n",
        "47      * Acidic: ASP, GLU\n",
        "48      * Basic: LYS, ARG, HIS\n",
        "49    - Only inter-chain salt bridges counted\n",
        "50\n",
        "51 3. Hydrophobic Contacts:\n",
        "52    - Distance cutoff: < 5.0 Å between any atoms of residue pairs\n",
        "53    - Hydrophobic residues considered:\n",
        "54      * ALA, VAL, LEU, ILE, MET, PHE, TRP, PRO\n",
        "55    - Only inter-chain contacts counted\n",
        "56\n",
        "57 4. Buried Surface Area:\n",
        "58    - Calculated using FreeSASA algorithm\n",
        "59    - Uses default atomic radii from FreeSASA (based on NACCESS/RSA)\n",
        "60    - Process:\n",
        "61      * First calculates SASA for entire complex\n",
        "62      * Then calculates SASA for each chain individually\n",
        "63      * BSA = (Sum of individual chain SASAs - Complex SASA) / 2\n",
        "64    - Units: Å²\n",
        "65    - Inter-chain burial only (interface area)\n",
        "66    - Probe radius: 1.4 Å (water molecule)\n",
        "67    - Resolution: 100 points/atom (FreeSASA default)\n",
        "68\n",
        "69 5. Interface Analysis (for structures with i_PAE < 7.5):\n",
        "70    - Core Region: Residues with >90% SASA burial upon complex formation\n",
        "71    - Rim Region: Residues with 10-90% SASA burial\n",
        "72    - Residue Classification:\n",
        "73      * Hydrophobic: ALA, VAL, LEU, ILE, MET, PHE, TRP, PRO\n",
        "74      * Polar: SER, THR, ASN, GLN, TYR, CYS\n",
        "75      * Charged: ASP, GLU, LYS, ARG, HIS\n",
        "76    - SASA calculated using FreeSASA with default parameters\n",
        "77      * Probe radius: 1.4 Å\n",
        "78      * Per-residue SASA summed from atomic areas\n",
        "79\n",
        "80 6. Clash Score:\n",
        "81    - Calculated as clashes per 1000 atoms\n",
        "82    - Clash defined as: non-bonded atoms closer than sum of vdW radii - 0.4 Å\n",
        "83    - Only inter-chain clashes considered\n",
        "84    - Hydrogen atoms excluded\n",
        "85    - Van der Waals radii used:\n",
        "86      * C: 1.7 Å\n",
        "87      * N: 1.55 Å\n",
        "88      * O: 1.52 Å\n",
        "89      * S: 1.8 Å\n",
        "90      * P: 1.8 Å\n",
        "91      * Halogens: F: 1.47 Å, Cl: 1.75 Å, Br: 1.85 Å, I: 1.98 Å\n",
        "92 \"\"\"\n",
        "93\n",
        "94 # Install required packages\n",
        "95 !pip install -q biopython pandas freesasa numpy matplotlib seaborn python-pptx plotly kaleido\n",
        "96\n",
        "97 # Import required libraries\n",
        "98 import os\n",
        "99 import sys\n",
        "100 import time\n",
        "101 import pandas as pd\n",
        "102 import matplotlib.pyplot as plt\n",
        "103 from google.colab import files, drive\n",
        "104 from pathlib import Path\n",
        "105 from typing import Dict, List, Optional, Tuple, Any\n",
        "106 from Bio import PDB\n",
        "107 from Bio.PDB.PDBIO import PDBIO\n",
        "108 from Bio.PDB.Polypeptide import is_aa\n",
        "109 from Bio.PDB.Structure import Structure\n",
        "110 import freesasa\n",
        "111 import numpy as np\n",
        "112 import seaborn as sns\n",
        "113 from pptx import Presentation\n",
        "114 from pptx.util import Inches, Cm, Pt\n",
        "115 import plotly.graph_objects as go\n",
        "116 from plotly.subplots import make_subplots\n",
        "117\n",
        "118 # Custom exception for structure validation\n",
        "119 class StructureValidationError(Exception):\n",
        "120     pass\n",
        "121 # ===============================\n",
        "122 # Structure Analysis Functions\n",
        "123 # ===============================\n",
        "124\n",
        "125 def validate_pdb_file(file_path: str) -> bool:\n",
        "126     \"\"\"Validates if file exists and has proper PDB format.\"\"\"\n",
        "127     if not os.path.exists(file_path):\n",
        "128         raise FileNotFoundError(f\"PDB file not found: {file_path}\")\n",
        "129     try:\n",
        "130         with open(file_path, 'r') as f:\n",
        "131             first_line = f.readline()\n",
        "132             if not any(marker in first_line for marker in ['HEADER', 'ATOM', 'MODEL']):\n",
        "133                 raise StructureValidationError(f\"Invalid PDB: {file_path}\")\n",
        "134     except UnicodeDecodeError:\n",
        "135         raise StructureValidationError(f\"Not a valid text file: {file_path}\")\n",
        "136     return True\n",
        "137\n",
        "138 def safe_structure_load(parser: PDB.PDBParser, file_path: str) -> Optional[Structure]:\n",
        "139     \"\"\"Safely loads PDB structure with error handling.\"\"\"\n",
        "140     try:\n",
        "141         validate_pdb_file(file_path)\n",
        "142         structure = parser.get_structure('protein', file_path)\n",
        "143         if not list(structure.get_models()):\n",
        "144             raise StructureValidationError(\"No models\")\n",
        "145         if not list(list(structure.get_models())[0].get_chains()):\n",
        "146             raise StructureValidationError(\"No chains\")\n",
        "147         return structure\n",
        "148     except Exception as e:\n",
        "149         print(f\"Error loading {file_path}: {str(e)}\")\n",
        "150         return None\n",
        "151\n",
        "152 def calculate_buried_surface_area(pdb_file: str) -> Tuple[Optional[float], Optional[Dict[str, float]]]:\n",
        "153     \"\"\"Calculates buried surface area between chains.\"\"\"\n",
        "154     parser = PDB.PDBParser(QUIET=True)\n",
        "155     structure = safe_structure_load(parser, pdb_file)\n",
        "156     if not structure:\n",
        "157         return None, None\n",
        "158     try:\n",
        "159         chains = list(structure.get_chains())\n",
        "160         if len(chains) < 2:\n",
        "161             print(f\"Warning: {pdb_file} has fewer than 2 chains\")\n",
        "162             return None, None\n",
        "163\n",
        "164         combined_structure = freesasa.Structure(pdb_file)\n",
        "165         result = freesasa.calc(combined_structure)\n",
        "166         total_area = result.totalArea()\n",
        "167\n",
        "168         chain_areas = {}\n",
        "169         io = PDBIO()\n",
        "170         temp_files = []\n",
        "171\n",
        "172         for chain in chains:\n",
        "173             new_structure = PDB.Structure.Structure('temp')\n",
        "174             new_model = PDB.Model.Model(0)\n",
        "175             new_structure.add(new_model)\n",
        "176             new_model.add(chain.copy())\n",
        "177\n",
        "178             temp_file = f\"temp_chain_{chain.id}.pdb\"\n",
        "179             temp_files.append(temp_file)\n",
        "180\n",
        "181             io.set_structure(new_structure)\n",
        "182             io.save(temp_file)\n",
        "183\n",
        "184             chain_structure = freesasa.Structure(temp_file)\n",
        "185             chain_result = freesasa.calc(chain_structure)\n",
        "186             chain_areas[chain.id] = chain_result.totalArea()\n",
        "187\n",
        "188         for temp_file in temp_files:\n",
        "189             if os.path.exists(temp_file):\n",
        "190                 os.remove(temp_file)\n",
        "191\n",
        "192         total_individual_area = sum(chain_areas.values())\n",
        "193         buried_surface_area = abs(total_individual_area - total_area) / 2\n",
        "194         return buried_surface_area, chain_areas\n",
        "195\n",
        "196     except Exception as e:\n",
        "197         print(f\"Error calculating BSA for {pdb_file}: {str(e)}\")\n",
        "198         return None, None\n",
        "199\n",
        "200 def calculate_hydrogen_bonds(structure: Structure) -> int:\n",
        "201     \"\"\"Calculates number of hydrogen bonds between chains.\"\"\"\n",
        "202     try:\n",
        "203         h_bonds = 0\n",
        "204         for chain1 in structure.get_chains():\n",
        "205             for chain2 in structure.get_chains():\n",
        "206                 if chain1.id >= chain2.id:\n",
        "207                     continue\n",
        "208                 for res1 in chain1.get_residues():\n",
        "209                     if not is_aa(res1):\n",
        "210                         continue\n",
        "211                     for res2 in chain2.get_residues():\n",
        "212                         if not is_aa(res2):\n",
        "213                             continue\n",
        "214                         if 'O' in res1 and 'N' in res2:\n",
        "215                             distance = res1['O'] - res2['N']\n",
        "216                             if distance < 3.5:\n",
        "217                                 h_bonds += 1\n",
        "218         return h_bonds\n",
        "219     except Exception as e:\n",
        "220         print(f\"Error calculating H-bonds: {str(e)}\")\n",
        "221         return 0\n",
        "222 def calculate_hydrophobic_contacts(structure: Structure) -> int:\n",
        "223     \"\"\"\n",
        "224     Calculates number of hydrophobic contacts between chains.\n",
        "225     Considers residues ALA, VAL, LEU, ILE, MET, PHE, TRP, PRO.\n",
        "226     Contact is counted if distance < 5.0 Å.\n",
        "227     \"\"\"\n",
        "228     try:\n",
        "229         hydrophobic_residues = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'TRP', 'PRO'}\n",
        "230         contacts = 0\n",
        "231         for chain1 in structure.get_chains():\n",
        "232             for chain2 in structure.get_chains():\n",
        "233                 if chain1.id >= chain2.id:\n",
        "234                     continue\n",
        "235                 for res1 in chain1.get_residues():\n",
        "236                     if not is_aa(res1) or res1.get_resname() not in hydrophobic_residues:\n",
        "237                         continue\n",
        "238                     for res2 in chain2.get_residues():\n",
        "239                         if not is_aa(res2) or res2.get_resname() not in hydrophobic_residues:\n",
        "240                             continue\n",
        "241                         min_distance = float('inf')\n",
        "242                         for atom1 in res1.get_atoms():\n",
        "243                             for atom2 in res2.get_atoms():\n",
        "244                                 distance = atom1 - atom2\n",
        "245                                 min_distance = min(min_distance, distance)\n",
        "246                         if min_distance < 5.0:\n",
        "247                             contacts += 1\n",
        "248         return contacts\n",
        "249     except Exception as e:\n",
        "250         print(f\"Error calculating hydrophobic contacts: {str(e)}\")\n",
        "251         return 0\n",
        "252\n",
        "253 def calculate_salt_bridges(structure: Structure) -> int:\n",
        "254     \"\"\"\n",
        "255     Calculates number of salt bridges between chains.\n",
        "256     Salt bridge is counted between ASP/GLU and LYS/ARG/HIS if distance < 4.0 Å.\n",
        "257     \"\"\"\n",
        "258     try:\n",
        "259         acidic = {'ASP', 'GLU'}\n",
        "260         basic = {'LYS', 'ARG', 'HIS'}\n",
        "261         salt_bridges = 0\n",
        "262         for chain1 in structure.get_chains():\n",
        "263             for chain2 in structure.get_chains():\n",
        "264                 if chain1.id >= chain2.id:\n",
        "265                     continue\n",
        "266                 for res1 in chain1.get_residues():\n",
        "267                     if not is_aa(res1):\n",
        "268                         continue\n",
        "269                     res1_name = res1.get_resname()\n",
        "270                     for res2 in chain2.get_residues():\n",
        "271                         if not is_aa(res2):\n",
        "272                             continue\n",
        "273                         res2_name = res2.get_resname()\n",
        "274                         if ((res1_name in acidic and res2_name in basic) or\n",
        "275                             (res1_name in basic and res2_name in acidic)):\n",
        "276                             min_distance = float('inf')\n",
        "277                             for atom1 in res1.get_atoms():\n",
        "278                                 for atom2 in res2.get_atoms():\n",
        "279                                     distance = atom1 - atom2\n",
        "280                                     min_distance = min(min_distance, distance)\n",
        "281                             if min_distance < 4.0:\n",
        "282                                 salt_bridges += 1\n",
        "283         return salt_bridges\n",
        "284     except Exception as e:\n",
        "285         print(f\"Error calculating salt bridges: {str(e)}\")\n",
        "286         return 0\n",
        "287\n",
        "288 def save_results_as_df(results: List[Dict[str, Any]], output_file: str) -> pd.DataFrame:\n",
        "289     \"\"\"\n",
        "290     Converts analysis results to DataFrame and saves to CSV.\n",
        "291     Extracts design and variant numbers from filenames.\n",
        "292     \"\"\"\n",
        "293     analysis_data = []\n",
        "294     for result in results:\n",
        "295         filename = result['file_name'].replace('.pdb', '')\n",
        "296         try:\n",
        "297             design_num = int(filename.split('design')[1].split('_')[0])\n",
        "298             variant_num = int(filename.split('_n')[1])\n",
        "299             analysis_data.append({\n",
        "300                 'design': design_num,\n",
        "301                 'n': variant_num,\n",
        "302                 'buried_surface_area': result['buried_surface_area'] if result['buried_surface_area'] else 0,\n",
        "303                 'hydrogen_bonds': result['hydrogen_bonds'],\n",
        "304                 'hydrophobic_contacts': result['hydrophobic_contacts'],\n",
        "305                 'salt_bridges': result['salt_bridges']\n",
        "306             })\n",
        "307         except Exception as e:\n",
        "308             print(f\"Error parsing filename {filename}: {str(e)}\")\n",
        "309             continue\n",
        "310\n",
        "311     df = pd.DataFrame(analysis_data)\n",
        "312     df = df.sort_values(['design', 'n']).reset_index(drop=True)\n",
        "313     df.to_csv(output_file, index=False)\n",
        "314     print(f\"Saved structure analysis to {output_file}\")\n",
        "315     return df\n",
        "316\n",
        "317 def merge_with_af2_scores(structure_df: pd.DataFrame, af2_scores_file: str) -> pd.DataFrame:\n",
        "318     \"\"\"Merges structural analysis results with AF2 scores.\"\"\"\n",
        "319     af2_df = pd.read_csv(af2_scores_file)\n",
        "320     merged_df = pd.merge(af2_df, structure_df, on=['design', 'n'], how='left')\n",
        "321     merged_df = merged_df.sort_values(['design', 'n']).reset_index(drop=True)\n",
        "322     return merged_df\n",
        "323 # ===============================\n",
        "324 # Interface Analysis Functions\n",
        "325 # ===============================\n",
        "326\n",
        "327 def calculate_residue_sasa(structure: Structure, chain_id: str, complex: bool = True) -> Dict[str, float]:\n",
        "328     \"\"\"\n",
        "329     Calculates SASA for each residue in a chain.\n",
        "330\n",
        "331     Args:\n",
        "332         structure: PDB Structure object\n",
        "333         chain_id: Chain identifier\n",
        "334         complex: If True, calculates SASA in context of complex; if False, treats chain in isolation\n",
        "335\n",
        "336     Returns:\n",
        "337         Dictionary of residue IDs and their SASA values\n",
        "338     \"\"\"\n",
        "339     # Create temporary PDB for SASA calculation\n",
        "340     io = PDBIO()\n",
        "341     if not complex:\n",
        "342         # Create new structure with just the chain of interest\n",
        "343         new_structure = PDB.Structure.Structure('temp')\n",
        "344         new_model = PDB.Model.Model(0)\n",
        "345         new_structure.add(new_model)\n",
        "346         target_chain = structure[0][chain_id]\n",
        "347         new_model.add(target_chain)\n",
        "348         structure = new_structure\n",
        "349\n",
        "350     io.set_structure(structure)\n",
        "351     temp_file = f\"temp_sasa_{chain_id}.pdb\"\n",
        "352     io.save(temp_file)\n",
        "353\n",
        "354     # Calculate SASA\n",
        "355     freesasa_struct = freesasa.Structure(temp_file)\n",
        "356     result = freesasa.calc(freesasa_struct)\n",
        "357\n",
        "358     # Get per-residue SASA\n",
        "359     residue_sasa = {}\n",
        "360     chain = structure[0][chain_id]\n",
        "361     for residue in chain:\n",
        "362         res_id = f\"{residue.get_resname()}_{residue.id[1]}\"\n",
        "363         sasa = sum(result.residueAreas()[chain_id].residueAreas[residue.id[1]].total)\n",
        "364         residue_sasa[res_id] = sasa\n",
        "365\n",
        "366     # Cleanup\n",
        "367     os.remove(temp_file)\n",
        "368     return residue_sasa\n",
        "369\n",
        "370 def analyze_interface_details(structure: Structure) -> Dict:\n",
        "371     \"\"\"\n",
        "372     Performs comprehensive interface analysis.\n",
        "373\n",
        "374     Calculates:\n",
        "375     1. Core/Rim classification (>90% burial for core, 10-90% for rim)\n",
        "376     2. Residue composition analysis\n",
        "377     3. Interface shape parameters\n",
        "378     \"\"\"\n",
        "379     results = {}\n",
        "380\n",
        "381     # Residue classifications\n",
        "382     hydrophobic = {'ALA', 'VAL', 'LEU', 'ILE', 'MET', 'PHE', 'TRP', 'PRO'}\n",
        "383     polar = {'SER', 'THR', 'ASN', 'GLN', 'TYR', 'CYS'}\n",
        "384     charged = {'ASP', 'GLU', 'LYS', 'ARG', 'HIS'}\n",
        "385\n",
        "386     core_residues = {'hydrophobic': 0, 'polar': 0, 'charged': 0}\n",
        "387     rim_residues = {'hydrophobic': 0, 'polar': 0, 'charged': 0}\n",
        "388\n",
        "389     # Analyze each chain\n",
        "390     for chain in structure.get_chains():\n",
        "391         # Calculate SASA for isolated chain\n",
        "392         monomer_sasa = calculate_residue_sasa(structure, chain.id, complex=False)\n",
        "393         # Calculate SASA in complex\n",
        "394         complex_sasa = calculate_residue_sasa(structure, chain.id, complex=True)\n",
        "395\n",
        "396         for residue_id, monomer_value in monomer_sasa.items():\n",
        "397             if monomer_value < 0.1:  # Skip buried residues\n",
        "398                 continue\n",
        "399\n",
        "400             complex_value = complex_sasa.get(residue_id, 0)\n",
        "401             burial_percent = (monomer_value - complex_value) / monomer_value * 100\n",
        "402\n",
        "403             # Get residue type\n",
        "404             res_name = residue_id.split('_')[0]\n",
        "405             if res_name in hydrophobic:\n",
        "406                 res_type = 'hydrophobic'\n",
        "407             elif res_name in polar:\n",
        "408                 res_type = 'polar'\n",
        "409             elif res_name in charged:\n",
        "410                 res_type = 'charged'\n",
        "411             else:\n",
        "412                 continue\n",
        "413\n",
        "414             # Classify as core or rim\n",
        "415             if burial_percent > 90:\n",
        "416                 core_residues[res_type] += 1\n",
        "417             elif burial_percent > 10:\n",
        "418                 rim_residues[res_type] += 1\n",
        "419\n",
        "420     # Calculate statistics\n",
        "421     total_core = sum(core_residues.values())\n",
        "422     total_rim = sum(rim_residues.values())\n",
        "423\n",
        "424     results = {\n",
        "425         'core_count': total_core,\n",
        "426         'rim_count': total_rim,\n",
        "427         'core_rim_ratio': total_core / max(1, total_rim),\n",
        "428         'core_hydrophobic': round(100 * core_residues['hydrophobic'] / max(1, total_core)),\n",
        "429         'core_polar': round(100 * core_residues['polar'] / max(1, total_core)),\n",
        "430         'core_charged': round(100 * core_residues['charged'] / max(1, total_core)),\n",
        "431         'rim_hydrophobic': round(100 * rim_residues['hydrophobic'] / max(1, total_rim)),\n",
        "432         'rim_polar': round(100 * rim_residues['polar'] / max(1, total_rim)),\n",
        "433         'rim_charged': round(100 * rim_residues['charged'] / max(1, total_rim))\n",
        "434     }\n",
        "435\n",
        "436     return results\n",
        "437\n",
        "438 def create_clash_score(structure: Structure) -> float:\n",
        "439     \"\"\"\n",
        "440     Calculates clash score for structure.\n",
        "441\n",
        "442     Clash defined as:\n",
        "443     - Non-bonded atoms closer than sum of van der Waals radii minus 0.4Å\n",
        "444     - Only considers inter-chain clashes\n",
        "445     - Hydrogens not considered\n",
        "446     \"\"\"\n",
        "447     # Van der Waals radii (Å)\n",
        "448     vdw_radii = {\n",
        "449         'C': 1.7, 'N': 1.55, 'O': 1.52, 'S': 1.8,\n",
        "450         'P': 1.8, 'F': 1.47, 'Cl': 1.75, 'Br': 1.85, 'I': 1.98\n",
        "451     }\n",
        "452\n",
        "453     clash_count = 0\n",
        "454     total_atoms = 0\n",
        "455\n",
        "456     # Iterate through chain pairs\n",
        "457     chains = list(structure.get_chains())\n",
        "458     for i, chain1 in enumerate(chains):\n",
        "459         for chain2 in chains[i+1:]:\n",
        "460             # Get heavy atoms\n",
        "461             atoms1 = [atom for atom in chain1.get_atoms()\n",
        "462                      if atom.element != 'H' and atom.element in vdw_radii]\n",
        "463             atoms2 = [atom for atom in chain2.get_atoms()\n",
        "464                      if atom.element != 'H' and atom.element in vdw_radii]\n",
        "465\n",
        "466             # Check for clashes\n",
        "467             for atom1 in atoms1:\n",
        "468                 for atom2 in atoms2:\n",
        "469                     distance = atom1 - atom2\n",
        "470                     min_distance = vdw_radii[atom1.element] + vdw_radii[atom2.element] - 0.4\n",
        "471\n",
        "472                     if distance < min_distance:\n",
        "473                         clash_count += 1\n",
        "474\n",
        "475             total_atoms += len(atoms1) + len(atoms2)\n",
        "476\n",
        "477     # Calculate clashes per 1000 atoms\n",
        "478     clash_score = (1000 * clash_count) / max(1, total_atoms)\n",
        "479     return clash_score\n",
        "480 # ===============================\n",
        "481 # Visualization Functions\n",
        "482 # ===============================\n",
        "483\n",
        "484 def create_pptx_plots(df: pd.DataFrame, output_dir: str, timestamp: str):\n",
        "485     \"\"\"\n",
        "486     Creates PowerPoint presentation with four slides:\n",
        "487     1. Structure-function correlation plots\n",
        "488     2. iPAE visualization\n",
        "489     3. Top 10 lowest iPAE sequences\n",
        "490     4. Detailed interface analysis for low iPAE structures\n",
        "491     \"\"\"\n",
        "492     # Initialize presentation\n",
        "493     prs = Presentation()\n",
        "494     prs.slide_width = Cm(21)\n",
        "495     prs.slide_height = Cm(29.7)\n",
        "496\n",
        "497     # First slide - correlation plots\n",
        "498     print(\"Creating correlation plots...\")\n",
        "499     slide1 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "500\n",
        "501     fig, axes = plt.subplots(3, 2, figsize=(8.27, 11.69))\n",
        "502     axes = axes.flatten()\n",
        "503\n",
        "504     y_vars = ['i_ptm', 'rmsd', 'buried_surface_area',\n",
        "505               'hydrogen_bonds', 'hydrophobic_contacts', 'salt_bridges']\n",
        "506     titles = ['iPTM', 'RMSD (Å)', 'Buried Surface Area (Å²)',\n",
        "507              '# of Hydrogen Bonds', '# of Hydrophobic Contacts', '# of Salt Bridges']\n",
        "508\n",
        "509     for ax, y_var, title in zip(axes, y_vars, titles):\n",
        "510         sns.scatterplot(data=df, x='i_pae', y=y_var, ax=ax, color='black', marker='x', s=16)\n",
        "511         ax.set_xlabel('i_PAE')\n",
        "512         ax.set_ylabel(title)\n",
        "513         ax.set_title(title)\n",
        "514         ax.set_facecolor('white')\n",
        "515\n",
        "516     fig.patch.set_facecolor('white')\n",
        "517     plt.tight_layout()\n",
        "518\n",
        "519     temp_img1 = os.path.join(output_dir, 'temp_plots1.png')\n",
        "520     plt.savefig(temp_img1, bbox_inches='tight', dpi=300, facecolor='white')\n",
        "521     plt.close()\n",
        "522\n",
        "523     left = Cm(2)\n",
        "524     top = Cm(2)\n",
        "525     slide1.shapes.add_picture(temp_img1, left, top)\n",
        "526\n",
        "527     # Second slide - iPAE visualization\n",
        "528     print(\"Creating iPAE visualization...\")\n",
        "529     slide2 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "530\n",
        "531     fig = make_subplots(\n",
        "532         rows=4,\n",
        "533         cols=1,\n",
        "534         vertical_spacing=0.08,\n",
        "535         subplot_titles=[f\"Designs {i*8}-{(i+1)*8-1}\" for i in range(4)]\n",
        "536     )\n",
        "537\n",
        "538     rows_per_subplot = 512  # 8 designs × 64 sequences = 512 rows per subplot\n",
        "539     colors = ['black', 'red']\n",
        "540\n",
        "541     for i in range(4):\n",
        "542         start_idx = i * rows_per_subplot\n",
        "543         end_idx = start_idx + rows_per_subplot\n",
        "544         chunk = df.iloc[start_idx:end_idx].copy()\n",
        "545\n",
        "546         for design_num in chunk['design'].unique():\n",
        "547             mask = chunk['design'] == design_num\n",
        "548             color = colors[design_num % 2]\n",
        "549\n",
        "550             fig.add_trace(\n",
        "551                 go.Bar(\n",
        "552                     x=chunk[mask].index,\n",
        "553                     y=chunk[mask]['i_pae'],\n",
        "554                     showlegend=False,\n",
        "555                     marker_color=color,\n",
        "556                     width=1,\n",
        "557                 ),\n",
        "558                 row=i+1,\n",
        "559                 col=1\n",
        "560             )\n",
        "561\n",
        "562         fig.update_yaxes(\n",
        "563             range=[0, 30],\n",
        "564             title_text='iPAE' if i == 1 else None,\n",
        "565             row=i+1,\n",
        "566             col=1\n",
        "567         )\n",
        "568\n",
        "569         design_numbers = sorted(chunk['design'].unique())\n",
        "570         fig.update_xaxes(\n",
        "571             tickmode='array',\n",
        "572             ticktext=design_numbers,\n",
        "573             tickvals=[start_idx + (j*64) + 32 for j in range(len(design_numbers))],\n",
        "574             row=i+1,\n",
        "575             col=1,\n",
        "576             title_text='Design Number' if i == 3 else None\n",
        "577         )\n",
        "578\n",
        "579     fig.update_layout(\n",
        "580         title='iPAE Scores by Design Number and Sequence (Scale: 0-30)',\n",
        "581         height=1000,\n",
        "582         width=1200,\n",
        "583         showlegend=False,\n",
        "584         margin=dict(t=50, b=50, r=150, l=50),\n",
        "585         paper_bgcolor='white',\n",
        "586         plot_bgcolor='white'\n",
        "587     )\n",
        "588\n",
        "589     temp_img2 = os.path.join(output_dir, 'temp_plots2.png')\n",
        "590     fig.write_image(temp_img2)\n",
        "591\n",
        "592     left = Cm(1)\n",
        "593     top = Cm(1)\n",
        "594     slide2.shapes.add_picture(temp_img2, left, top)\n",
        "595     # Third slide - Top 10 sequences\n",
        "596     print(\"Creating top 10 sequences slide...\")\n",
        "597     slide3 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "598\n",
        "599     # Get top 10 lowest i_PAE sequences\n",
        "600     top_10_sequences = df.nsmallest(10, 'i_pae')[['design', 'n', 'i_pae', 'seq']]\n",
        "601\n",
        "602     # Add title\n",
        "603     title = slide3.shapes.title\n",
        "604     title.text = \"Top 10 Sequences (Lowest i_PAE Scores)\"\n",
        "605\n",
        "606     # Create text box for sequences\n",
        "607     left = Cm(2)\n",
        "608     top = Cm(4)\n",
        "609     width = Cm(17)\n",
        "610     height = Cm(20)\n",
        "611     textbox = slide3.shapes.add_textbox(left, top, width, height)\n",
        "612     text_frame = textbox.text_frame\n",
        "613     text_frame.clear()\n",
        "614\n",
        "615     # Add sequences\n",
        "616     for _, row in top_10_sequences.iterrows():\n",
        "617         sequence = row['seq'].split('/')[1].strip()\n",
        "618         p = text_frame.add_paragraph()\n",
        "619         p.text = f\">d{row['design']}n{row['n']} (i_PAE: {row['i_pae']:.4f})\\n{sequence}\"\n",
        "620         p.font.name = 'Courier New'\n",
        "621         p.font.size = Pt(8)\n",
        "622         p.line_spacing = 1.0\n",
        "623\n",
        "624     # Fourth slide - Detailed interface analysis\n",
        "625     print(\"Creating interface analysis for low i_PAE structures...\")\n",
        "626     slide4 = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "627\n",
        "628     # Add title\n",
        "629     title = slide4.shapes.title\n",
        "630     title.text = \"Detailed Interface Analysis (Structures with i_PAE < 7.5)\"\n",
        "631\n",
        "632     # Create text box\n",
        "633     left = Cm(2)\n",
        "634     top = Cm(4)\n",
        "635     width = Cm(17)\n",
        "636     height = Cm(20)\n",
        "637     textbox = slide4.shapes.add_textbox(left, top, width, height)\n",
        "638     text_frame = textbox.text_frame\n",
        "639     text_frame.clear()\n",
        "640\n",
        "641     # Get low i_PAE structures\n",
        "642     low_ipae_structures = df[df['i_pae'] < 7.5].sort_values('i_pae')\n",
        "643\n",
        "644     if len(low_ipae_structures) == 0:\n",
        "645         p = text_frame.add_paragraph()\n",
        "646         p.text = \"No structures found with i_PAE < 7.5\"\n",
        "647         p.font.name = 'Courier New'\n",
        "648         p.font.size = Pt(8)\n",
        "649     else:\n",
        "650         parser = PDB.PDBParser(QUIET=True)\n",
        "651\n",
        "652         for _, row in low_ipae_structures.iterrows():\n",
        "653             pdb_file = os.path.join(os.path.dirname(output_dir),\n",
        "654                                   f\"design{row['design']}_n{row['n']}.pdb\")\n",
        "655             structure = safe_structure_load(parser, pdb_file)\n",
        "656\n",
        "657             if structure:\n",
        "658                 interface_analysis = analyze_interface_details(structure)\n",
        "659                 clash_score = create_clash_score(structure)\n",
        "660\n",
        "661                 p = text_frame.add_paragraph()\n",
        "662                 p.text = (\n",
        "663                     f\"Structure d{row['design']}n{row['n']} (i_PAE: {row['i_pae']:.2f})\\n\"\n",
        "664                     f\"Buried Surface Area: {row['buried_surface_area']:.1f} Å²\\n\"\n",
        "665                     f\"Clash Score: {clash_score:.2f}\\n\"\n",
        "666                     f\"Interface Analysis:\\n\"\n",
        "667                     f\"  Core Residues: {interface_analysis['core_count']}\\n\"\n",
        "668                     f\"  Rim Residues: {interface_analysis['rim_count']}\\n\"\n",
        "669                     f\"  Core/Rim ratio: {interface_analysis['core_rim_ratio']:.2f}\\n\"\n",
        "670                     f\"  Core Composition:\\n\"\n",
        "671                     f\"    Hydrophobic: {interface_analysis['core_hydrophobic']}%\\n\"\n",
        "672                     f\"    Polar: {interface_analysis['core_polar']}%\\n\"\n",
        "673                     f\"    Charged: {interface_analysis['core_charged']}%\\n\"\n",
        "674                     f\"  Rim Composition:\\n\"\n",
        "675                     f\"    Hydrophobic: {interface_analysis['rim_hydrophobic']}%\\n\"\n",
        "676                     f\"    Polar: {interface_analysis['rim_polar']}%\\n\"\n",
        "677                     f\"    Charged: {interface_analysis['rim_charged']}%\\n\"\n",
        "678                     f\"----------------------------------------\\n\"\n",
        "679                 )\n",
        "680                 p.font.name = 'Courier New'\n",
        "681                 p.font.size = Pt(8)\n",
        "682                 p.line_spacing = 1.0\n",
        "683\n",
        "684     # Save PowerPoint\n",
        "685     output_basename = os.path.basename(output_dir)\n",
        "686     pptx_path = os.path.join(output_dir, f\"{output_basename}_{timestamp}_analysis.pptx\")\n",
        "687     prs.save(pptx_path)\n",
        "688\n",
        "689     # Clean up temporary files\n",
        "690     os.remove(temp_img1)\n",
        "691     os.remove(temp_img2)\n",
        "692     print(f\"Saved PowerPoint to {pptx_path}\")\n",
        "693 # ===============================\n",
        "694 # Main Processing Functions\n",
        "695 # ===============================\n",
        "696\n",
        "697 def process_multiple_pdb_files(pdb_directory: str, af2_scores_file: str = None) -> pd.DataFrame:\n",
        "698     \"\"\"\n",
        "699     Main processing function that:\n",
        "700     1. Analyzes all PDB files in directory\n",
        "701     2. Merges with AF2 scores\n",
        "702     3. Generates visualizations and outputs\n",
        "703     4. Saves sequences to FASTA\n",
        "704     \"\"\"\n",
        "705     if not os.path.exists(pdb_directory):\n",
        "706         raise FileNotFoundError(f\"Directory not found: {pdb_directory}\")\n",
        "707\n",
        "708     # Get timestamp for file naming\n",
        "709     timestamp = time.strftime(\"%y%m%d\")\n",
        "710\n",
        "711     # Initialize results\n",
        "712     results = []\n",
        "713     parser = PDB.PDBParser(QUIET=True)\n",
        "714     pdb_files = [f for f in os.listdir(pdb_directory) if f.endswith('.pdb')]\n",
        "715\n",
        "716     if not pdb_files:\n",
        "717         print(f\"No PDB files found in {pdb_directory}\")\n",
        "718         return pd.DataFrame()\n",
        "719\n",
        "720     print(f\"Processing {len(pdb_files)} PDB files...\")\n",
        "721     total_files = len(pdb_files)\n",
        "722\n",
        "723     # Process each PDB file\n",
        "724     for idx, file_name in enumerate(pdb_files, 1):\n",
        "725         pdb_file = os.path.join(pdb_directory, file_name)\n",
        "726         print(f\"Processing file {idx}/{total_files}: {file_name}\")\n",
        "727\n",
        "728         structure = safe_structure_load(parser, pdb_file)\n",
        "729         if not structure:\n",
        "730             continue\n",
        "731\n",
        "732         # Calculate structural parameters\n",
        "733         buried_surface_area, chain_areas = calculate_buried_surface_area(pdb_file)\n",
        "734         h_bonds = calculate_hydrogen_bonds(structure)\n",
        "735         hydrophobic = calculate_hydrophobic_contacts(structure)\n",
        "736         salt_bridges = calculate_salt_bridges(structure)\n",
        "737\n",
        "738         results.append({\n",
        "739             'file_name': file_name,\n",
        "740             'buried_surface_area': buried_surface_area,\n",
        "741             'hydrogen_bonds': h_bonds,\n",
        "742             'hydrophobic_contacts': hydrophobic,\n",
        "743             'salt_bridges': salt_bridges,\n",
        "744             'chain_areas': chain_areas\n",
        "745         })\n",
        "746\n",
        "747     # Save structural analysis\n",
        "748     output_basename = os.path.basename(pdb_directory)\n",
        "749     structure_csv = os.path.join(pdb_directory, f\"{output_basename}_{timestamp}_structure.csv\")\n",
        "750     structure_df = save_results_as_df(results, structure_csv)\n",
        "751\n",
        "752     # If AF2 scores exist, merge and create visualizations\n",
        "753     if af2_scores_file and os.path.exists(af2_scores_file):\n",
        "754         print(f\"Merging with AF2 scores from {af2_scores_file}\")\n",
        "755         final_df = merge_with_af2_scores(structure_df, af2_scores_file)\n",
        "756\n",
        "757         # Save combined analysis\n",
        "758         combined_csv = os.path.join(pdb_directory, f\"{output_basename}_{timestamp}_combined.csv\")\n",
        "759         final_df.to_csv(combined_csv, index=False)\n",
        "760         print(f\"Saved combined results to {combined_csv}\")\n",
        "761\n",
        "762         # Create PowerPoint plots\n",
        "763         create_pptx_plots(final_df, pdb_directory, timestamp)\n",
        "764\n",
        "765         # Save sequences to FASTA\n",
        "766         fasta_path = os.path.join(pdb_directory, f\"{output_basename}_{timestamp}_sequences.fasta\")\n",
        "767         with open(fasta_path, 'w') as f:\n",
        "768             for _, row in final_df.iterrows():\n",
        "769                 sequence = row['seq'].split('/')[1].strip()\n",
        "770                 header = f\">d{row['design']}n{row['n']}\"\n",
        "771                 f.write(f\"{header}\\n{sequence}\\n\")\n",
        "772         print(f\"Saved sequences to {fasta_path}\")\n",
        "773\n",
        "774         return final_df\n",
        "775     return structure_df\n",
        "776\n",
        "777 # ===============================\n",
        "778 # Main Execution\n",
        "779 # ===============================\n",
        "780\n",
        "781 if __name__ == \"__main__\":\n",
        "782     # Mount Google Drive\n",
        "783     drive.mount('/content/drive')\n",
        "784\n",
        "785     # Set directory containing PDB files and AF2 scores\n",
        "786     pdb_directory = '/content/drive/MyDrive/PDB-files/202501xx/3NOB-70-110-all_pdb'  # Update this path\n",
        "787     af2_scores_path = os.path.join(pdb_directory, 'af2_scores.csv')\n",
        "788\n",
        "789     if not os.path.exists(af2_scores_path):\n",
        "790         af2_scores_path = None\n",
        "791         print(\"No AF2 scores file found - will generate structure analysis only\")\n",
        "792\n",
        "793     print(\"\\nStarting analysis...\")\n",
        "794     print(f\"Processing PDB files from: {pdb_directory}\")\n",
        "795\n",
        "796     try:\n",
        "797         results_df = process_multiple_pdb_files(pdb_directory, af2_scores_path)\n",
        "798         print(\"\\nAnalysis completed successfully!\")\n",
        "799     except Exception as e:\n",
        "800         print(f\"\\nError during analysis: {str(e)}\")\n",
        "801         raise\n"
      ]
    }
  ]
}